{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8a8553",
   "metadata": {},
   "source": [
    "# RF-DETR-L: Fine-tuning and Evaluation\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Install required dependencies\n",
    "2. Prepare dataset for training\n",
    "3. Fine-tune RF-DETR-L on a custom dataset\n",
    "4. Run inference on test images\n",
    "5. Calculate and visualize evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7ee87",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f0ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Install rfdetr package and required dependencies\n",
    "# !pip install rfdetr \"rfdetr[metrics]\" \"rfdetr[onnxexport]\"\n",
    "# !pip install supervision opencv-python matplotlib seaborn pyyaml\n",
    "\n",
    "# Check CUDA availability \n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888c48e",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be8e5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 17:39:14.004079: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-17 17:39:14.019820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750162154.041176  342645 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750162154.047224  342645 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-17 17:39:14.067016: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import supervision as sv\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from rfdetr import RFDETRLarge\n",
    "from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818509b",
   "metadata": {},
   "source": [
    "## 3. Dataset Conversion and Preparation\n",
    "\n",
    "RF-DETR expects datasets in COCO format, while YOLOv8 uses YOLO format. We need to convert the YOLOv8 dataset format to COCO format. Additionally, RF-DETR uses a \"valid\" directory instead of the \"val\" directory used by YOLOv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b82d8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coco_structure():\n",
    "    \"\"\"Create the basic COCO JSON structure\"\"\"\n",
    "    coco_output = {\n",
    "        \"info\": {\n",
    "            \"description\": \"Converted from YOLO format\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2023,\n",
    "            \"contributor\": \"converter\",\n",
    "            \"date_created\": \"\"\n",
    "        },\n",
    "        \"licenses\": [{\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Unknown\",\n",
    "            \"url\": \"\"\n",
    "        }],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    return coco_output\n",
    "\n",
    "def yolo_to_coco_coordinates(bbox, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Convert YOLO bbox format (x_center, y_center, width, height) normalized\n",
    "    to COCO bbox format (x_min, y_min, width, height) in absolute coordinates\n",
    "    \"\"\"\n",
    "    x_center, y_center, width, height = bbox\n",
    "    \n",
    "    # Denormalize the coordinates\n",
    "    x_center *= image_width\n",
    "    y_center *= image_height\n",
    "    width *= image_width\n",
    "    height *= image_height\n",
    "    \n",
    "    # Convert to COCO format (x_min, y_min, width, height)\n",
    "    x_min = x_center - width / 2\n",
    "    y_min = y_center - height / 2\n",
    "    \n",
    "    return [float(x_min), float(y_min), float(width), float(height)]\n",
    "\n",
    "def convert_yolo_to_coco(yolo_dir, coco_dir, class_names=None, split_name=\"train\"):\n",
    "    \"\"\"\n",
    "    Convert YOLO dataset to COCO format\n",
    "    \n",
    "    Args:\n",
    "        yolo_dir (str): Source directory with YOLO format annotations\n",
    "        coco_dir (str): Target directory for COCO format\n",
    "        class_names (list): List of class names\n",
    "        split_name (str): Name of the dataset split (train, val/valid, test)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    coco_split_name = 'valid' if split_name == 'val' else split_name\n",
    "    coco_split_dir = os.path.join(coco_dir, coco_split_name)\n",
    "    os.makedirs(coco_split_dir, exist_ok=True)\n",
    "    \n",
    "    # Get images and labels paths - adjust for nested structure\n",
    "    # Check multiple possible directory structures\n",
    "    possible_image_dirs = [\n",
    "        os.path.join(yolo_dir, split_name, \"images\"),  # dataset/train/images/\n",
    "        os.path.join(yolo_dir, \"images\", split_name),  # dataset/images/train/\n",
    "        os.path.join(yolo_dir, split_name)             # dataset/train/\n",
    "    ]\n",
    "    \n",
    "    images_dir = None\n",
    "    for dir_path in possible_image_dirs:\n",
    "        if os.path.exists(dir_path):\n",
    "            images_dir = dir_path\n",
    "            break\n",
    "    \n",
    "    if not images_dir:\n",
    "        print(f\"Could not find images directory for {split_name} split\")\n",
    "        return False\n",
    "    \n",
    "    possible_label_dirs = [\n",
    "        os.path.join(yolo_dir, split_name, \"labels\"),  # dataset/train/labels/\n",
    "        os.path.join(yolo_dir, \"labels\", split_name),  # dataset/labels/train/\n",
    "        os.path.join(yolo_dir, \"labels\")               # dataset/labels/\n",
    "    ]\n",
    "    \n",
    "    labels_dir = None\n",
    "    for dir_path in possible_label_dirs:\n",
    "        if os.path.exists(dir_path):\n",
    "            labels_dir = dir_path\n",
    "            break\n",
    "    \n",
    "    if not labels_dir:\n",
    "        print(f\"Could not find labels directory for {split_name} split\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Using images from: {images_dir}\")\n",
    "    print(f\"Using labels from: {labels_dir}\")\n",
    "    \n",
    "    # Get image file extensions\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(images_dir, f\"*{ext}\")))\n",
    "        image_files.extend(glob.glob(os.path.join(images_dir, f\"*{ext.upper()}\")))\n",
    "    \n",
    "    # Verify that we found image files\n",
    "    if len(image_files) == 0:\n",
    "        print(f\"No image files found in {images_dir}\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"Found {len(image_files)} images in {images_dir}\")\n",
    "    \n",
    "    # Create COCO JSON structure\n",
    "    coco_output = create_coco_structure()\n",
    "    \n",
    "    # Add categories based on given class names\n",
    "    if not class_names:\n",
    "        # Try to read classes from dataset.yaml\n",
    "        yaml_path = os.path.join(yolo_dir, \"data.yaml\")\n",
    "        if os.path.exists(yaml_path):\n",
    "            try:\n",
    "                with open(yaml_path, 'r') as f:\n",
    "                    data = yaml.safe_load(f)\n",
    "                    class_names = data.get('names', [])\n",
    "                    if isinstance(class_names, dict):\n",
    "                        # Convert dict to list if needed\n",
    "                        max_id = max(class_names.keys())\n",
    "                        class_list = [\"unknown\"] * (max_id + 1)\n",
    "                        for class_id, class_name in class_names.items():\n",
    "                            class_list[class_id] = class_name\n",
    "                        class_names = class_list\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading yaml: {e}\")\n",
    "                class_names = []\n",
    "    \n",
    "    if not class_names:\n",
    "        # Create generic class names if nothing is provided\n",
    "        label_files = glob.glob(os.path.join(labels_dir, \"*.txt\"))\n",
    "        unique_class_ids = set()\n",
    "        for label_file in label_files:\n",
    "            if os.path.exists(label_file):\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            unique_class_ids.add(class_id)\n",
    "        \n",
    "        class_names = [f\"class_{i}\" for i in range(max(unique_class_ids) + 1 if unique_class_ids else 0)]\n",
    "    \n",
    "    # Add categories to COCO structure\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        category = {\n",
    "            \"id\": i + 1,  # COCO uses 1-indexed category IDs\n",
    "            \"name\": class_name,\n",
    "            \"supercategory\": \"none\"\n",
    "        }\n",
    "        coco_output[\"categories\"].append(category)\n",
    "    \n",
    "    print(f\"Processing {len(image_files)} images\")\n",
    "    \n",
    "    # Process each image\n",
    "    annotation_id = 1  # COCO uses 1-indexed annotation IDs\n",
    "    for image_id, image_path in enumerate(image_files, 1):  # COCO uses 1-indexed image IDs\n",
    "        # Get the filename and extension\n",
    "        file_name = os.path.basename(image_path)\n",
    "        file_base = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        # Try to open and get image dimensions\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            width, height = image.size\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Add image to COCO structure\n",
    "        coco_image = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"license\": 1\n",
    "        }\n",
    "        coco_output[\"images\"].append(coco_image)\n",
    "        \n",
    "        # Copy image to COCO directory\n",
    "        shutil.copy2(image_path, os.path.join(coco_split_dir, file_name))\n",
    "        \n",
    "        # Find corresponding label file\n",
    "        label_path = os.path.join(labels_dir, f\"{file_base}.txt\")\n",
    "        \n",
    "        # If label file exists, process annotations\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        # YOLO format: class_id x_center y_center width height\n",
    "                        class_id = int(parts[0])\n",
    "                        bbox = list(map(float, parts[1:5]))\n",
    "                        \n",
    "                        # Convert YOLO coordinates to COCO coordinates\n",
    "                        x_min, y_min, box_width, box_height = yolo_to_coco_coordinates(bbox, width, height)\n",
    "                        \n",
    "                        # Add annotation to COCO structure\n",
    "                        coco_annotation = {\n",
    "                            \"id\": annotation_id,\n",
    "                            \"image_id\": image_id,\n",
    "                            \"category_id\": class_id + 1,  # COCO uses 1-indexed category IDs\n",
    "                            \"bbox\": [x_min, y_min, box_width, box_height],\n",
    "                            \"area\": box_width * box_height,\n",
    "                            \"segmentation\": [],\n",
    "                            \"iscrowd\": 0\n",
    "                        }\n",
    "                        coco_output[\"annotations\"].append(coco_annotation)\n",
    "                        annotation_id += 1\n",
    "    \n",
    "    # Save the COCO JSON file\n",
    "    with open(os.path.join(coco_split_dir, \"_annotations.coco.json\"), 'w') as f:\n",
    "        json.dump(coco_output, f, indent=4)\n",
    "    \n",
    "    print(f\"Converted {len(image_files)} images with {annotation_id-1} annotations to COCO format.\")\n",
    "    print(f\"COCO dataset saved to: {coco_split_dir}\")\n",
    "    print(f\"Categories: {[cat['name'] for cat in coco_output['categories']]}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f1650",
   "metadata": {},
   "source": [
    "## 4. Dataset Configuration\n",
    "\n",
    "Now let's set up the dataset paths and convert the YOLOv8 dataset to COCO format for RF-DETR-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882a6655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source YOLO dataset directory: ../dataset_split\n",
      "Target COCO dataset directory: ../dataset_split_coco\n",
      "Found classes in YAML: ['car']\n",
      "COCO dataset already exists. Skipping conversion.\n",
      "Found 438 images in ../dataset_split_coco/train\n",
      "Found 93 images in ../dataset_split_coco/valid\n",
      "Found 95 images in ../dataset_split_coco/test\n",
      "Dataset structure looks correct for RF-DETR!\n"
     ]
    }
   ],
   "source": [
    "# Define source YOLO dataset and target COCO dataset directories\n",
    "SOURCE_DATASET_DIR = \"../dataset_split\"  # The YOLOv8 dataset directory (same as in YOLOv8 notebook)\n",
    "COCO_DATASET_DIR = \"../dataset_split_coco\"  # Where to save the converted COCO dataset\n",
    "\n",
    "# Create directories for COCO dataset\n",
    "os.makedirs(COCO_DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# Define paths for RF-DETR\n",
    "DATASET_DIR = COCO_DATASET_DIR\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATASET_DIR, \"valid\")  # Note: RF-DETR uses \"valid\" instead of \"val\"\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"test\")\n",
    "\n",
    "print(f\"Source YOLO dataset directory: {SOURCE_DATASET_DIR}\")\n",
    "print(f\"Target COCO dataset directory: {DATASET_DIR}\")\n",
    "\n",
    "# Check if dataset.yaml exists to get class names\n",
    "yaml_path = os.path.join(SOURCE_DATASET_DIR, \"data.yaml\")\n",
    "class_names = None\n",
    "if os.path.exists(yaml_path):\n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            class_names = data.get('names', None)\n",
    "            if isinstance(class_names, dict):\n",
    "                # Convert dict to list if needed\n",
    "                max_id = max(class_names.keys())\n",
    "                class_list = [\"unknown\"] * (max_id + 1)\n",
    "                for class_id, class_name in class_names.items():\n",
    "                    class_list[class_id] = class_name\n",
    "                class_names = class_list\n",
    "            print(f\"Found classes in YAML: {class_names}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading yaml: {e}\")\n",
    "        class_names = None\n",
    "\n",
    "# Check if COCO dataset already exists\n",
    "if (os.path.exists(TRAIN_DIR) and \n",
    "    os.path.exists(VAL_DIR) and \n",
    "    os.path.exists(TEST_DIR) and\n",
    "    os.path.exists(os.path.join(TRAIN_DIR, \"_annotations.coco.json\")) and\n",
    "    os.path.exists(os.path.join(VAL_DIR, \"_annotations.coco.json\")) and\n",
    "    os.path.exists(os.path.join(TEST_DIR, \"_annotations.coco.json\"))):\n",
    "    print(\"COCO dataset already exists. Skipping conversion.\")\n",
    "else:\n",
    "    print(\"Converting YOLO dataset to COCO format...\")\n",
    "    \n",
    "    # Remove any partial conversions to start fresh\n",
    "    import shutil\n",
    "    for dir_path in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "        if os.path.exists(dir_path):\n",
    "            shutil.rmtree(dir_path)\n",
    "    \n",
    "    # Convert train split\n",
    "    print(\"\\nConverting train split...\")\n",
    "    convert_yolo_to_coco(SOURCE_DATASET_DIR, DATASET_DIR, class_names, \"train\")\n",
    "    \n",
    "    # Convert validation split (val → valid)\n",
    "    print(\"\\nConverting validation split...\")\n",
    "    convert_yolo_to_coco(SOURCE_DATASET_DIR, DATASET_DIR, class_names, \"val\")\n",
    "    \n",
    "    # Convert test split\n",
    "    print(\"\\nConverting test split...\")\n",
    "    convert_yolo_to_coco(SOURCE_DATASET_DIR, DATASET_DIR, class_names, \"test\")\n",
    "\n",
    "# Verify dataset structure for RF-DETR\n",
    "expected_structure = True\n",
    "for dir_path in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(f\"Warning: {dir_path} does not exist\")\n",
    "        expected_structure = False\n",
    "    elif not os.path.exists(os.path.join(dir_path, '_annotations.coco.json')):\n",
    "        print(f\"Warning: COCO annotations missing in {dir_path}\")\n",
    "        expected_structure = False\n",
    "    else:\n",
    "        image_count = len([f for f in os.listdir(dir_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"Found {image_count} images in {dir_path}\")\n",
    "\n",
    "if expected_structure:\n",
    "    print(\"Dataset structure looks correct for RF-DETR!\")\n",
    "else:\n",
    "    print(\"Please fix the dataset structure before proceeding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285aaeef",
   "metadata": {},
   "source": [
    "## 5. Model Initialization\n",
    "\n",
    "Initialize the RF-DETR-L model. This is the large variant of RF-DETR with 128M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356e68f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize RF-DETR-L model with default weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRFDETRLarge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRF-DETR-L model initialized with pretrained weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Optimize model for inference\u001b[39;00m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/rfdetr/detr.py:24\u001b[0m, in \u001b[0;36mRFDETR.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_download_pretrain_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/rfdetr/detr.py:29\u001b[0m, in \u001b[0;36mRFDETR.maybe_download_pretrain_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmaybe_download_pretrain_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mdownload_pretrain_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrain_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/rfdetr/main.py:67\u001b[0m, in \u001b[0;36mdownload_pretrain_weights\u001b[0;34m(pretrain_weights, redownload)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m redownload \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pretrain_weights):\n\u001b[1;32m     64\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading pretrained weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrain_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     )\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mHOSTED_MODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpretrain_weights\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrain_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/rfdetr/util/files.py:6\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_file\u001b[39m(url, filename):\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     total_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, tqdm(\n\u001b[1;32m      9\u001b[0m         desc\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m     10\u001b[0m         total\u001b[38;5;241m=\u001b[39mtotal_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m         unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     14\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/connection.py:704\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m    706\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.globalenv/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize RF-DETR-L model with default weights\n",
    "model = RFDETRLarge()\n",
    "print(\"RF-DETR-L model initialized with pretrained weights\")\n",
    "\n",
    "# Optimize model for inference\n",
    "model = model.optimize_for_inference()\n",
    "print(\"Model optimized for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699f273",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning RF-DETR-L Model\n",
    "\n",
    "Now we'll fine-tune our RF-DETR-L model on the custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory for training outputs\n",
    "results_dir = os.path.join(os.getcwd(), \"rf_detr_l_results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Define training parameters matching the YOLO models for fair comparison\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    # Determine GPU memory capacity to set appropriate batch size and gradient accumulation steps\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # Convert to GB\n",
    "        print(f\"GPU memory: {gpu_memory:.2f} GB\")\n",
    "        \n",
    "        if gpu_memory > 20:  # High-end GPU like A100\n",
    "            batch_size = 16\n",
    "            grad_accum_steps = 1\n",
    "        elif gpu_memory > 12:  # Mid-range GPU like RTX 3080\n",
    "            batch_size = 8\n",
    "            grad_accum_steps = 2\n",
    "        else:  # Consumer GPU like T4 or lower\n",
    "            batch_size = 4\n",
    "            grad_accum_steps = 4\n",
    "    else:\n",
    "        # CPU training (not recommended)\n",
    "        batch_size = 2\n",
    "        grad_accum_steps = 8\n",
    "    \n",
    "    print(f\"Using batch_size={batch_size}, grad_accum_steps={grad_accum_steps}\")\n",
    "    \n",
    "    # Start training with hyperparameters matched to YOLO models\n",
    "    try:\n",
    "        model.train(\n",
    "            dataset_dir=DATASET_DIR,\n",
    "            epochs=100,                    # Same as YOLO (100 epochs)\n",
    "            batch_size=batch_size,\n",
    "            grad_accum_steps=grad_accum_steps,\n",
    "            lr=0.0005,                     # Same as YOLO (0.0005)\n",
    "            optimizer='AdamW',             # Same as YOLO (AdamW)\n",
    "            weight_decay=0.001,            # Same as YOLO (0.001)\n",
    "            output_dir=results_dir,\n",
    "            tensorboard=True,\n",
    "            early_stopping=True,\n",
    "            early_stopping_patience=20,    # Same as YOLO patience (20)\n",
    "            checkpoint_interval=5          # Save checkpoint every 5 epochs\n",
    "        )\n",
    "        print(f\"Training completed. Model saved to: {results_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Training failed with error: {e}\")\n",
    "else:\n",
    "    print(\"Dataset directory does not exist. Skipping training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065f954",
   "metadata": {},
   "source": [
    "## 7. Model Inference and Evaluation\n",
    "\n",
    "Let's evaluate our fine-tuned model on test images. If training was skipped, we'll use the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the appropriate model - either fine-tuned or pretrained\n",
    "if os.path.exists(os.path.join(results_dir, \"checkpoint.pth\")):\n",
    "    print(\"Loading fine-tuned model...\")\n",
    "    eval_model = RFDETRLarge(pretrain_weights=os.path.join(results_dir, \"checkpoint.pth\"))\n",
    "    eval_model = eval_model.optimize_for_inference()\n",
    "else:\n",
    "    print(\"Using pretrained model since no fine-tuned model is available...\")\n",
    "    eval_model = model  # Using the pretrained model initialized earlier\n",
    "\n",
    "# Run inference on a sample image to test the model\n",
    "sample_url = \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\"\n",
    "sample_image = Image.open(io.BytesIO(requests.get(sample_url).content))\n",
    "\n",
    "detections = eval_model.predict(sample_image, threshold=0.5)\n",
    "\n",
    "# Visualize the detections\n",
    "labels = [\n",
    "    f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
    "    for class_id, confidence\n",
    "    in zip(detections.class_id, detections.confidence)\n",
    "]\n",
    "\n",
    "annotated_image = sample_image.copy()\n",
    "annotated_image = sv.BoxAnnotator().annotate(annotated_image, detections)\n",
    "annotated_image = sv.LabelAnnotator().annotate(annotated_image, detections, labels)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.imshow(annotated_image)\n",
    "plt.axis('off')\n",
    "plt.title('Sample Detection Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cff002",
   "metadata": {},
   "source": [
    "## 8. Batch Inference\n",
    "\n",
    "RF-DETR supports batch inference which processes multiple images in a single forward pass for improved efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch inference with multiple sample images\n",
    "sample_urls = [\n",
    "    \"https://media.roboflow.com/notebooks/examples/dog-2.jpeg\",\n",
    "    \"https://media.roboflow.com/notebooks/examples/dog-3.jpeg\",\n",
    "    \"https://media.roboflow.com/dog.jpeg\"\n",
    "]\n",
    "\n",
    "# Download sample images\n",
    "sample_images = []\n",
    "for url in sample_urls:\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(requests.get(url).content))\n",
    "        sample_images.append(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image from {url}: {e}\")\n",
    "\n",
    "# Run batch inference\n",
    "if sample_images:\n",
    "    batch_detections = eval_model.predict(sample_images, threshold=0.5)\n",
    "    \n",
    "    # Create a grid of visualizations\n",
    "    fig, axs = plt.subplots(1, len(sample_images), figsize=(18, 6))\n",
    "    if len(sample_images) == 1:\n",
    "        axs = [axs]  # Make iterable for single image case\n",
    "        \n",
    "    for i, (img, detections) in enumerate(zip(sample_images, batch_detections)):\n",
    "        labels = [\n",
    "            f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
    "            for class_id, confidence\n",
    "            in zip(detections.class_id, detections.confidence)\n",
    "        ]\n",
    "        \n",
    "        annotated_image = img.copy()\n",
    "        annotated_image = sv.BoxAnnotator().annotate(annotated_image, detections)\n",
    "        annotated_image = sv.LabelAnnotator().annotate(annotated_image, detections, labels)\n",
    "        \n",
    "        axs[i].imshow(annotated_image)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(f'Image {i+1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No sample images available for batch inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8229a75",
   "metadata": {},
   "source": [
    "## 9. Performance Metrics on Test Set\n",
    "\n",
    "Let's evaluate the model performance on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average precision at various IoU thresholds\n",
    "def evaluate_on_test_set(model, test_dir):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and calculate metrics\n",
    "    \"\"\"\n",
    "    test_images_dir = os.path.join(test_dir, 'images') if os.path.exists(os.path.join(test_dir, 'images')) else test_dir\n",
    "    annotation_path = os.path.join(test_dir, '_annotations.coco.json')\n",
    "    \n",
    "    if not os.path.exists(test_images_dir) or not os.path.exists(annotation_path):\n",
    "        print(\"Test directory or annotations not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        from pycocotools.coco import COCO\n",
    "        from pycocotools.cocoeval import COCOeval\n",
    "    except ImportError:\n",
    "        print(\"pycocotools not installed. Install with: pip install pycocotools\")\n",
    "        return None\n",
    "    \n",
    "    # Load ground truth annotations\n",
    "    coco_gt = COCO(annotation_path)\n",
    "    \n",
    "    # Store model predictions in COCO format\n",
    "    predictions = []\n",
    "    \n",
    "    # Get all test images\n",
    "    test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"Running inference on {len(test_images)} test images...\")\n",
    "    for img_file in tqdm(test_images):\n",
    "        img_path = os.path.join(test_images_dir, img_file)\n",
    "        img_id = int(os.path.splitext(img_file)[0]) if img_file[0].isdigit() else None\n",
    "        \n",
    "        # Skip images without valid ID mapping\n",
    "        if img_id is None:\n",
    "            for ann_img in coco_gt.imgs.values():\n",
    "                if os.path.basename(ann_img['file_name']) == img_file:\n",
    "                    img_id = ann_img['id']\n",
    "                    break\n",
    "        \n",
    "        if img_id is None:\n",
    "            continue\n",
    "            \n",
    "        # Run inference\n",
    "        image = Image.open(img_path)\n",
    "        detections = model.predict(image, threshold=0.1)  # Lower threshold for evaluation\n",
    "        \n",
    "        # Convert detections to COCO format\n",
    "        for box, score, class_id in zip(detections.xyxy, detections.confidence, detections.class_id):\n",
    "            x1, y1, x2, y2 = box.tolist() if hasattr(box, 'tolist') else box\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            predictions.append({\n",
    "                'image_id': img_id,\n",
    "                'category_id': class_id + 1,  # COCO uses 1-indexed categories\n",
    "                'bbox': [x1, y1, width, height],\n",
    "                'score': float(score)\n",
    "            })\n",
    "    \n",
    "    # If no predictions were made\n",
    "    if not predictions:\n",
    "        print(\"No predictions generated\")\n",
    "        return None\n",
    "        \n",
    "    # Create COCO format results\n",
    "    coco_dt = coco_gt.loadRes(predictions)\n",
    "    \n",
    "    # Run evaluation\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    # Extract metrics\n",
    "    metrics = {\n",
    "        'AP@0.5': coco_eval.stats[1],  # AP at IoU=0.50\n",
    "        'AP@0.75': coco_eval.stats[2],  # AP at IoU=0.75\n",
    "        'AP@0.5:0.95': coco_eval.stats[0],  # AP at IoU=0.50:0.95\n",
    "        'AP_small': coco_eval.stats[3],  # AP for small objects\n",
    "        'AP_medium': coco_eval.stats[4],  # AP for medium objects\n",
    "        'AP_large': coco_eval.stats[5],  # AP for large objects\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run evaluation if test set is available\n",
    "if os.path.exists(TEST_DIR):\n",
    "    try:\n",
    "        metrics = evaluate_on_test_set(eval_model, TEST_DIR)\n",
    "        if metrics:\n",
    "            print(\"\\nTest set evaluation results:\")\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "            \n",
    "            # Plot metrics\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.bar(metrics.keys(), metrics.values())\n",
    "            plt.title('RF-DETR-L Performance Metrics')\n",
    "            plt.ylabel('Average Precision')\n",
    "            plt.ylim(0, 1.0)\n",
    "            for i, v in enumerate(metrics.values()):\n",
    "                plt.text(i, v+0.02, f\"{v:.3f}\", ha='center')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Evaluation failed: {e}\")\n",
    "else:\n",
    "    print(\"Test directory not found. Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712e83f",
   "metadata": {},
   "source": [
    "## 10. Class-wise Performance Analysis\n",
    "\n",
    "Let's analyze the model's performance for each class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a804cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class-wise metrics\n",
    "def get_class_metrics(coco_eval):\n",
    "    \"\"\"\n",
    "    Extract class-wise metrics from COCO evaluation\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries\n",
    "    metrics = {}\n",
    "    \n",
    "    # Get class-wise AP at different IoU thresholds\n",
    "    for i, class_id in enumerate(coco_eval.params.catIds):\n",
    "        metrics[class_id] = {\n",
    "            'AP@0.5': coco_eval.eval['precision'][0, :, i, 0, 2].mean(),\n",
    "            'AP@0.75': coco_eval.eval['precision'][5, :, i, 0, 2].mean(),\n",
    "            'AP@0.5:0.95': np.mean([coco_eval.eval['precision'][t, :, i, 0, 2].mean() \n",
    "                                  for t in range(len(coco_eval.params.iouThrs))])\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Get class-wise metrics if test set is available\n",
    "if os.path.exists(TEST_DIR) and 'coco_eval' in locals():\n",
    "    try:\n",
    "        class_metrics = get_class_metrics(coco_eval)\n",
    "        \n",
    "        # Read class names from the COCO annotations\n",
    "        with open(os.path.join(TEST_DIR, '_annotations.coco.json'), 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "            coco_categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "        \n",
    "        # Create DataFrame for visualization\n",
    "        metrics_data = []\n",
    "        for class_id, metrics in class_metrics.items():\n",
    "            class_name = coco_categories.get(class_id, f\"Class {class_id}\")\n",
    "            metrics_data.append({\n",
    "                'Class': class_name,\n",
    "                'AP@0.5': metrics['AP@0.5'],\n",
    "                'AP@0.75': metrics['AP@0.75'],\n",
    "                'AP@0.5:0.95': metrics['AP@0.5:0.95']\n",
    "            })\n",
    "        \n",
    "        class_df = pd.DataFrame(metrics_data)\n",
    "        display(class_df)\n",
    "        \n",
    "        # Plot class-wise AP@0.5\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        sns.barplot(x='Class', y='AP@0.5', data=class_df)\n",
    "        plt.title('AP@0.5 for Each Class')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Class-wise analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404c102",
   "metadata": {},
   "source": [
    "## 11. Export Model for Deployment\n",
    "\n",
    "Let's export our fine-tuned model to ONNX format for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create export directory\n",
    "export_dir = os.path.join(results_dir, \"exported_models\")\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "# Export model to ONNX format\n",
    "try:\n",
    "    # Use fine-tuned model if available, otherwise use pretrained\n",
    "    if os.path.exists(os.path.join(results_dir, \"checkpoint.pth\")):\n",
    "        export_model = RFDETRLarge(pretrain_weights=os.path.join(results_dir, \"checkpoint.pth\"))\n",
    "    else:\n",
    "        export_model = eval_model\n",
    "        \n",
    "    # Export to ONNX\n",
    "    export_model.export(output_dir=export_dir)\n",
    "    \n",
    "    print(f\"Model exported to {export_dir}\")\n",
    "    print(\"Available exported files:\")\n",
    "    for file in os.listdir(export_dir):\n",
    "        print(f\"- {file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638f674",
   "metadata": {},
   "source": [
    "## 12. Comparing YOLOv8 and RF-DETR-L\n",
    "\n",
    "Now that we've trained and evaluated both models on the same dataset, let's compare their performance:\n",
    "\n",
    "1. **Model Architecture**: YOLOv8 uses a CNN-based architecture optimized for speed, while RF-DETR-L uses a transformer-based architecture that can better capture contextual relationships\n",
    "\n",
    "2. **Performance Metrics**: Compare the mAP values from both models\n",
    "   - YOLOv8x mAP50: (from YOLOv8 results)\n",
    "   - RF-DETR-L mAP50: (from RF-DETR-L results)\n",
    "\n",
    "3. **Inference Speed**:\n",
    "   - YOLOv8x is generally faster on consumer hardware\n",
    "   - RF-DETR-L provides better accuracy while still maintaining real-time performance\n",
    "\n",
    "4. **Object Detection Quality**:\n",
    "   - RF-DETR-L may perform better with complex scenes and overlapping objects\n",
    "   - YOLOv8 excels at detecting small objects at high speed\n",
    "\n",
    "5. **Model Size and Deployment**:\n",
    "   - YOLOv8x: ~130 MB\n",
    "   - RF-DETR-L: ~480 MB (compressed)\n",
    "\n",
    "The best model choice depends on your specific requirements for accuracy, speed, and available hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
